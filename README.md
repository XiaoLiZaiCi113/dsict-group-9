## README Generated by GPT
# JITLab — Day-Simulation & JIT Optimization (Food‑Ordering Case)

This project provides a lightweight setup to study how **JIT settings** influence **latency, throughput, and energy** under a realistic **time‑varying workload**.  
We model a **food‑ordering service** over a day (compressed timeline) with **lunch/dinner peaks**, and we keep runs **laptop‑friendly**.

---

## Files in this repo (essentials)
- `load_staged.py` — Stage‑based **open‑loop** load generator (fixed RPS per stage, weighted endpoints, concurrency cap).
- `day_profile.json` — Example **5‑minute stages** (10 s wall‑time each), encoding off‑peak, lunch peak, afternoon lull, dinner peak.
- `load_py.py` — Legacy **closed‑loop** load generator (as‑fast‑as‑possible workers, warm‑up + record).
- `plot.py` — Simple plotter for the per‑second CSV produced by the loaders.
- `monitor.py` — If present, sample CPU/RSS/energy (RAPL) once per second; the plotter can overlay it.

> Tip: Use **stage‑based open‑loop** for sustainability experiments (average‑day energy), and keep **closed‑loop** for capacity discovery.

---

## Requirements
- **Python 3.9+**
  ```bash
  python3 -m venv .venv && source .venv/bin/activate
  pip install httpx pandas matplotlib psutil
  ```
- **Target service** reachable at `--baseUrl` (e.g., a local JVM/Flask server exposing the endpoints you want to test).

---

## Option A — Day Simulation (Open‑Loop, Stage‑Based)
Each stage represents **5 real minutes** but runs for ~**10 seconds** on your laptop. This preserves diurnal shape without long runs.

**Run:**
```bash
python3 tools/load_staged.py \
  --baseUrl http://localhost:8080 \
  --stageFile tools/day_profile.json \
  --out runs/day_timeseries.csv
```

**Output columns (per second):**
```
ts, stage, rps, avg_ms, p50_ms, p95_ms, ok, err
```

**Stage file schema (JSON):**
```json
[
  {
    "label": "lunch_peak",
    "duration_sec": 10,                 // wall-time for this stage
    "represents_min": 5,                // real minutes represented (useful for weighting)
    "rate": 160,                        // target RPS (open-loop)
    "concurrency_cap": 40,              // max in-flight requests (laptop guardrail)
    "mix": {                            // endpoint weights (relative)
      "/feed": 0.20, "/search": 0.15, "/menu": 0.20,
      "/cart": 0.15, "/checkout": 0.10, "/status": 0.20
    },
    "payload": {                        // optional per-endpoint payloads
      "/search": [{"q":"sushi"}, {"q":"burger"}],   // list => random choice
      "/menu": { "id_pool": [1,2,3,4,5] },          // id_pool => inject random id
      "/checkout": { "cart_total": 2799, "payment": "card" }
    }
  }
]
```

**Laptop‑safe scaling guidelines**
- Discover sustainable RPS via a short ramp; set peak stages to **~60–75%** of that number.
- Concurrency cap heuristic: `cap ≈ rate × p99_latency_seconds` (e.g., 160 RPS × 0.20 s ⇒ cap ≈ 32).

---

## Option B — Closed‑Loop Microbenchmark (Legacy)
Use for baselines, warm‑up/JIT behavior studies:
```bash
python3 tools/load_py.py \
  --url http://localhost:8080/work/cpu \
  --body '{"iterations":2000,"payloadSize":20000}' \
  --concurrency 8 --warmupSec 10 --runSec 120 \
  --out runs/load_cpu.csv
```

---

## Automated Run: one_run_staged.py

For a **fully automated staged run** (monitor + staged loader + per-stage & comparison plots):

```bash
python3 tools/one_run_staged.py \
  --baseUrl http://localhost:8080 \
  --stageFile tools/day_profile.json \
  --title "JITLab Staged Run"
```

---

## Plotting
```bash
# Plot per-second load CSV (and optionally overlay monitor.csv if available)
MPLBACKEND=Agg python3 tools/plot.py \
  --load runs/load_cpu.csv \
  --monitor runs/monitor_cpu.csv \
  --title "CPU endpoint"
```
Produces PNGs such as **RPS vs Power**, **p95 latency**, **CPU% & RSS**, **Cumulative Energy**.

---

## Suggested JIT Experiments (server side)
Compare latency/throughput/energy under different JIT policies (examples shown for HotSpot):
```bash
# Control (no JIT)
java -Xint -jar app.jar

# C2 only (no tiering)
java -XX:-TieredCompilation -jar app.jar

# C1 only
java -XX:+TieredCompilation -XX:TieredStopAtLevel=1 -jar app.jar

# Compile sooner / fewer compiler threads
java -XX:CompileThreshold=1000 -XX:CICompilerCount=1 -jar app.jar

# Stable heap to de-noise GC
java -Xms1g -Xmx1g -jar app.jar
```

**Compare across stages:**
- Throughput (RPS), P50/P95, error%
- **Energy/query** & total energy (weight by `represents_min`)
- Warm‑up vs steady‑state behavior, tail spikes (deopts/GC)

---
